# Judgment-Driven Development

**Sprint Kit 설계 철학 — BMad Method 기반 실행 확장팩**

> Sprint Kit은 프로덕트 전문가가 가진 맥락을 최대한 활용하여 AI의 첫 생성 품질을 높이고,
> 고객 관점의 판단 시점에서만 사람의 시간을 사용하며,
> 필요할 때 전체 재생성으로 방향을 수정하는 — BMad Method 기반의 실행 확장팩이다.

---

## 배경: 두 시스템의 합성

### BMad Method — "신뢰할 수 있는 AI 협업"

BMad Method는 AI를 퍼실리테이터로 활용하는 Top-down 기획 프레임워크다.
12단계의 step-file 아키텍처를 통해 사용자가 매 단계에서 의사결정에 참여하고,
그 결과로 고품질의 기획 산출물(Product Brief, PRD, Architecture, Epics)을 만든다.

핵심 가치: **탐색과 발견을 통한 빈틈 없는 요구사항 정의**

### Sprint Kit — "결과물로 대화한다"

Sprint Kit은 BMad Method 위에서 동작하는 실행 레이어다.
사전 입력(회의록, 참고자료)과 기존 시스템 맥락을 자동 수집하여
AI가 기획 산출물을 생성하고, 프로덕트 전문가가 핵심 시점에서 판단한다.

핵심 가치: **구체적 결과물에 대한 전문가 판단을 통한 빠른 실현**

### 합성의 필요성

두 시스템은 대립하지 않는다. **사람의 지식이 어떤 형태로 존재하느냐**에 따라
다른 경로를 제공하며, 같은 산출물 포맷으로 합류하여 같은 실행 파이프라인으로 진행한다.

```
BMad Method (기반 플랫폼)
  ├─ 에이전트 프레임워크 (Mary, John, Winston, Sally, Bob...)
  ├─ 워크플로우 엔진 (step-file architecture)
  ├─ 퍼실리테이션 패턴 (A/P/C 메뉴, party mode)
  └─ 산출물 포맷 (PRD, Architecture, Epics)

Sprint Kit (BMad 위의 실행 확장팩)
  ├─ Input Layer: 사전 입력 처리 + brownfield 자동 수집
  ├─ Generation Layer: BMad 에이전트 자동 오케스트레이션
  ├─ Judgment Layer: Customer-Lens JP1/JP2
  ├─ Execution Layer: Specs → Deliverables → Prototype
  └─ Regeneration: 수정반영+전파 / 재생성 파이프라인
```

---

## 6원칙

### 원칙 1: Artifacts as Medium — 결과물이 대화의 매체다

> 추상적 질문이 아니라, 구체적 결과물에 대한 반응이 가장 정확하고 빠른 입력이다.

사람은 추상적 질문에는 부정확하게 답하지만, 구체적 결과물에는 정확하게 반응한다.

```
추상적 질문:  "검색 기능에서 뭐가 중요해요?"  → 부정확한 답
구체적 결과물: "이 검색 화면이 맞나요?"        → 정확한 판단

추상적 질문:  "어떤 API가 필요해요?"           → 모호한 답
구체적 결과물: "이 5개 엔드포인트로 충분한가요?" → 명확한 판단
```

이 원칙은 BMad Method의 "Facilitation Over Generation"을 확장한다.
BMad가 대화를 통해 발견을 촉진한다면,
Sprint Kit은 **결과물을 통해 판단을 촉진**한다.

두 접근 모두 사람의 전문성을 끌어내는 방법이며,
사용자의 맥락과 상황에 따라 더 효과적인 방식이 달라진다.

### 원칙 2: Input Reduces Cycles — 입력이 재생성 횟수를 줄인다

> 사전 입력(회의록, 참고자료, 기존 시스템 맥락)은 첫 생성의 품질을 높여서
> 재생성 횟수를 줄인다. 좋은 입력은 여러 번의 판단보다 효율적이다.

AI 생성 비용은 0이 아니다. 재생성 횟수가 늘어나면 사람의 판단 시간도 누적된다.

```
총 비용 = (사전 입력 비용) + (생성 비용 × 생성 횟수) + (판단 비용 × 판단 횟수)

사전 입력이 풍부하면:  생성 횟수 ↓, 판단 횟수 ↓  → 총 비용 ↓
사전 입력이 없으면:    생성 횟수 ↑, 판단 횟수 ↑  → 총 비용 ↑
```

Sprint Kit에서의 실현:
- `specs/{feature}/inputs/`: 회의록, 참고자료, 기존 문서를 넣는 곳
- Brownfield Scanner: 기존 시스템 맥락을 자동 수집하여 입력에 추가
- Brief: 사용자가 제공하는 최소한의 방향 설정

이 세 가지가 합쳐져서 AI의 첫 생성이 "대충 맞는" 수준이 아니라
"검토할 만한" 수준이 되게 한다.

**현실 예시**: 프로덕트 팀이 킥오프 미팅에서 2시간 동안 논의한 결과가
회의록으로 존재한다면, 이 회의록은 BMad 12단계 인터뷰에서 얻을 수 있는
대부분의 정보를 이미 담고 있다. 이것을 inputs/에 넣는 것만으로
AI의 PRD 첫 생성 품질이 크게 높아진다.

### 원칙 3: Regeneration Over Modification — 수정보다 재생성

> 수정이 아니라 재생성이 기본이다. 모든 AI 산출물은 소모품이되,
> 재생성 비용은 0이 아니므로 Input과 Judgment가 재생성 횟수를 최소화한다.

AI 시대 이전의 수정(patch) 방식:
```
문서 v1 → 피드백 → v1에서 일부 수정 → v1.1 → 피드백 → 일부 수정 → v1.2
문제: 수정이 누적되면 문서의 일관성이 깨짐
```

AI 시대의 재생성(regenerate) 방식:
```
문서 v1 → 피드백 → 피드백을 반영한 완전히 새로운 v2 생성 → 피드백 → v3 생성
장점: 매번 일관성 있는 결과물
전제: 사람의 판단(피드백)이 축적되어 다음 생성에 반영됨
```

**사람의 판단만이 축적되는 영속 자산이다. 나머지는 전부 재생성 가능하다.**

Sprint Kit에서의 실현:
- Circuit Breaker: 비상 모드가 아닌 정상적인 재생성 트리거
- JP Comment → 재생성: 피드백 규모에 따라 재생성 범위가 동적으로 결정됨
- JP Comment → 수정반영+전파: 소규모 피드백은 기존 산출물 내에서 양방향 전파 + Scope Gate 검증
- 어떤 처리 방식이든 사용자가 cost를 보고 선택함 (cost 투명성)

**현실적 균형**: 재생성 비용이 0이 아니기 때문에,
원칙 2(Input Reduces Cycles)가 재생성 횟수를 줄여주고,
원칙 4(Customer-Lens Judgment Points)가 올바른 시점에서 방향을 잡아주어
불필요한 재생성을 방지한다.

### 원칙 4: Customer-Lens Judgment Points — 고객 관점의 판단 시점

> 사람이 개입하는 시점은 "고객에게 어떤 제품이 서빙될지 판단할 수 있는 순간"에
> 배치된다. 판단은 반드시 구체적 결과물 위에서 이루어진다.

프로덕트 전문가의 정의:
- ~~개발자의 반대로서의 "비개발자"~~
- **고객에 대한 전문가이자, 어떤 결과물이 나와야 하는지 가장 잘 판단할 수 있는 사람**

이 정의에서 체크포인트가 도출된다:

**JP1 (Judgment Point 1): "고객에게 필요한 제품인가?"**
```
판단 대상:  요구사항, 사용자 시나리오, 기능 범위, 우선순위
판단 형식:  PRD의 핵심 내용을 고객 여정 서사(narrative)로 제시
            "고객이 A 상황에서 B를 하려 할 때, 시스템이 C를 제공합니다."
프로덕트 전문가의 판단:
  - "이 시나리오가 실제 고객 상황과 맞는가?"
  - "빠진 시나리오가 있는가?"
  - "우선순위가 맞는가?"
응답: Confirm / Comment
```

**JP2 (Judgment Point 2): "고객이 원하는 경험인가?"**
```
판단 대상:  프로토타입, 화면 흐름, 인터랙션
판단 형식:  동작하는 프로토타입 + 핵심 시나리오 가이드
            "시나리오 1을 직접 수행해보세요: 로그인 → 대시보드 → 기능 X"
프로덕트 전문가의 판단:
  - "이 화면 구성이 고객에게 자연스러운가?"
  - "기능이 고객 기대대로 동작하는가?"
  - "빠진 화면이나 흐름이 있는가?"
응답: Confirm / Comment
```

**Comment — 피드백이 방향을 수정한다:**

Comment를 선택하면 시스템이 피드백의 영향 범위를 분석하고,
수정반영+전파와 재생성 두 가지 옵션을 cost와 함께 제시한다.
사용자가 cost를 보고 선택한다.

```
JP1/JP2 → Comment → 피드백 입력
  → 시스템: 영향 분석
  → [수정반영+전파] N개 파일, ~M분, Scope Gate 검증 포함
  → [재생성] Phase X부터, ~M분
  → 사용자 선택 → 실행 → JP 복귀
```

재생성 범위는 피드백 규모에 따라 동적으로 결정된다.
작은 피드백은 Deliverables만, 큰 피드백은 PRD부터,
방향 전환이면 Brief 수정 후 Sprint 재시작까지.
JP2에서 요구사항 자체가 잘못됐다고 판단되면 재생성 범위가
자연스럽게 JP1 이전으로 확장된다 — 이것은 실패가 아니라
**구체적 결과물이 촉진한 정상적인 발견**이다.

**구조적 보조 — BMad 12단계의 가치를 체크리스트로 압축:**

JP1에서 프로덕트 전문가가 판단할 때, BMad 12단계가 발견하려는 것들을
구조적 체크리스트로 보조한다:
```
□ 모든 핵심 사용자 유형이 포함되었는가?
□ 엣지 케이스 시나리오가 고려되었는가?
□ 기존 기능과의 관계가 명확한가?
□ 성공 지표가 측정 가능한가?
```

이 체크리스트는 Bottom-up의 약점(빠진 것을 발견하기 어려움)을
Top-down의 강점(구조화된 탐색)으로 보완한다.

### 원칙 5: Knowledge Shape Determines Route — 지식의 형태가 경로를 결정한다

> 사람의 지식이 어떤 형태로 존재하느냐에 따라 경로가 달라진다.

```
사람의 지식 형태                     적합 경로
──────────────────────────────────────────────────
A. 풍부한 비정형 맥락                Bottom-up (Sprint Kit Auto Sprint)
   (회의록, 데이터, 경험)            AI가 구조화 → 사람이 판단 → 재생성

B. 미탐색 영역                      Top-down (BMad 12단계)
   (새 시장, 새 문제)                AI가 질문 → 사람이 발견 → AI가 구조화

C. 이미 구조화된 산출물              Direct (Sprint Kit /specs)
   (기존 PRD, 완성된 기획서)         바로 실행 파이프라인으로
```

**선택은 사용자의 맥락에 따라. 시스템이 강제하지 않는다.**

실제 사용 패턴 예시:
| 사용자 상황 | 입력 형태 | 적합 경로 | 진입점 |
|------------|----------|----------|--------|
| PM이 킥오프 미팅 후 | 회의록 + 참고자료 | Bottom-up | `/sprint feature-name` |
| 창업자가 새 제품 구상 | 아이디어만 | Top-down | `/create-product-brief` |
| 디자이너가 시안 기반 실행 | Figma URL + 설명 | Bottom-up | `/sprint feature-name` |
| 기존 PRD를 실행에 옮기기 | 완성된 PRD | Direct | `/specs feature-name` |
| 범위 파악용 빠른 프로토타입 | 한 줄 brief | Bottom-up | `/sprint "설명"` |

**Top-down과 Bottom-up은 "깊이"의 차이가 아니다:**
- Top-down의 깊이: 문제 정의의 정밀도 — "정확히 무엇을 만들어야 하는가"
- Bottom-up의 깊이: 판단의 정확도 — "이게 맞는 것인가"
- 둘 다 깊다. 깊은 곳이 다를 뿐이다.

### 원칙 6: Auto-Context, Human-Judgment — 맥락은 자동, 판단은 사람

> 기술적 맥락 수집은 AI가 자동으로 수행한다.
> 사람에게는 고객 영향으로 번역하여 판단만 요청한다.

Brownfield 환경에서 기존 시스템과의 관계를 파악하는 것은
프로덕트 전문가의 일이 아니다. AI가 자동으로 수집하고,
프로덕트 전문가에게는 판단에 필요한 형태로 번역하여 제시한다.

```
AI가 수집:                             사람에게 제시:
"기존 API /api/v1/tutors에              "기존 '튜터 관리' 기능에 영향이
 GET, POST, DELETE 엔드포인트            있습니다. 현재 튜터 목록 화면에서
 존재. TutorService 클래스에서            새로운 '차단' 기능이 추가되면,
 blockTutor 메서드 미구현.                기존 사용자 경험이 변경됩니다.
 DB에 tutor_block_list 테이블 없음"       허용하시겠어요?"
```

Sprint Kit에서의 실현:
- Brownfield Scanner: MCP 서버, document-project, local codebase에서 자동 수집
- brownfield-context.md: L1(도메인) → L2(행위) → L3(컴포넌트) → L4(코드) 계층 구조
- JP1/JP2에서: 기술적 brownfield 데이터를 고객 영향으로 번역하여 제시

---

## 현실의 프로덕트 팀 워크플로우와의 매핑

Sprint Kit은 현실의 프로덕트 팀이 일하는 방식에서 AI가 대체할 수 있는 부분을
대체하고, 사람이 잘하는 부분은 유지한다.

```
현실의 프로덕트 팀                       Sprint Kit 적용
──────────────────────────────────────────────────────────
1. 킥오프 미팅 (2시간)                  → inputs/에 회의록 저장 (~0분)
2. 누군가 PRD 초안 작성 (하루)           → ██ AI가 PRD 생성 ██ (~5분)
3. PRD 리뷰 미팅 (1시간)               → JP1: PRD 판단 (~10분)
4. PRD 수정 (반나절)                    → ██ 필요 시 AI 재생성 ██ (~3분)
5. 디자인 → 프로토타입 (일주일)          → ██ AI가 프로토타입 생성 ██ (~10분)
6. 프로토타입 리뷰 (1시간)              → JP2: 프로토타입 판단 (~15분)
7. 수정 → 최종 확정 (며칠)              → ██ 필요 시 AI 재생성 ██ (~10분)

사람 시간: ~25분 (기존: 4시간 30분 + 수 일의 대기)
```

**AI가 대체하는 것:** 구조화, 작성, 구현 (사람이 상대적으로 느린 작업)
**사람이 유지하는 것:** 맥락 제공, 판단, 방향 결정 (사람이 훨씬 정확한 작업)

---

## AI 시대의 개발 방법론 전환

### Waterfall → Agile의 교훈

Top-down(Waterfall) 개발이 "빈틈 없는 사전 정의"를 추구했지만,
현실에서는 빈틈을 0으로 만들 수 없었다. 이 한계를 인정하고
반복(iteration)을 통해 보완하는 것이 Agile의 핵심 통찰이었다.

### Agile → Judgment-Driven의 전환

Bottom-up(Judgment-Driven) 개발이 "AI가 만들고 사람이 판단"을 추구하지만,
현실에서는 AI 생성 비용과 시간이 0이 될 수 없다.
이 한계를 인정하고, **사전 입력으로 첫 생성 품질을 높이고
적절한 판단 시점에서 방향을 수정**하는 것이 Sprint Kit의 핵심 설계다.

```
Waterfall:  빈틈 없이 정의 → 한 번에 구현 (이상)
            빈틈 발견 → 되돌아가기 비용 큼 (현실)

Agile:      반복을 통해 점진적 개선 (해법)
            하지만 매 반복에 구현 비용 발생

JDD:        AI가 빠르게 생성 → 사람이 판단 → 재생성 (이상)
            재생성 비용 ≠ 0, 판단도 시간 소모 (현실)
            → 입력 품질 ↑ + 판단 시점 최적화 = 최소 재생성 (해법)
```

**이것이 현실에서 많은 사람들이 사용하는 서비스의 핵심이다.**
이론적 이상이 아니라, 실제 프로덕트 조직에서 동작하는 균형점을 찾는 것.

---

## 부록: 설계 논의 과정에서의 주요 통찰

### "비개발자"라는 프레이밍의 문제

초기 논의에서 Sprint Kit의 대상 사용자를 "비개발자"로 정의했다.
이 정의는 개발자의 반대(anti)로서 소거법적 정의이며,
실제 이 사용자들의 전문성을 포착하지 못한다.

**수정된 정의**: "고객에 대한 전문가, 어떤 결과물이 나와야 하는지
가장 잘 판단할 수 있는 사람" — 즉 프로덕트 전문가.

이 재정의가 체크포인트 설계에 미치는 영향:
- 기존: 기술적 품질 게이트 (Brief mapping %, Scope Gate 결과)
- 변경: 고객 관점 판단 시점 (고객 여정 서사, 경험 검증)

### "Deep vs Quick"이 아니라 "Top-down vs Bottom-up"

초기 논의에서 경로를 "탐색 깊이"로 분류했다 (Deep planning vs Quick execution).
이 프레이밍은 전형적인 개발자 시각으로, Bottom-up을 "얕은 것"으로 암시한다.

**수정된 프레이밍**: 두 경로 모두 깊다. 깊은 영역이 다르다.
- Top-down: 문제 정의의 정밀도가 깊다
- Bottom-up: 결과물에 대한 판단의 정확도가 깊다

### Bridge 개념의 해체

초기 설계에서는 BMad 산출물을 Sprint Kit으로 넘기는 "Bridge" 커맨드를 계획했다.
논의를 통해 이 개념이 불필요함을 발견:

1. 두 시스템의 산출물 포맷이 이미 동일하다 (같은 prd-format-guide 사용)
2. Sprint Kit의 `/specs`가 planning-artifacts 경로만 해소하면 연결된다
3. Bridge는 "두 시스템 사이의 번역기"이지만, 확장팩 모델에서는 번역이 필요 없다

**결론**: Sprint Kit은 BMad의 별도 시스템이 아니라 확장팩이므로,
연결점은 커맨드가 아니라 파일 포맷 계약(planning-artifacts/ 디렉토리)이다.

### "재생성 비용 ≈ 0" 가정의 현실적 수정

초기 논의에서 "AI 재생성 비용이 거의 0"이라는 전제로 설계를 진행했다.
현실적 검증:

```
Auto Sprint 전체 사이클: 5~15분
PRD 재생성: 2~5분
프로토타입 재생성: 5~10분
```

비용이 0은 아니다. 재생성 횟수가 늘면 사람의 판단 시간도 누적된다.
이 현실적 제약이 원칙 2(Input Reduces Cycles)의 존재 이유다.

**실용적 균형점**: 사전 입력과 brownfield 맥락으로 첫 생성 품질을 높여
재생성 횟수를 1~2회로 줄이는 것이 목표.

### 원칙 3의 실용적 보정 — 수정반영이 허용되는 조건

원칙 3은 "수정보다 재생성"을 기본으로 둔다. 산출물은 소모품이고,
피드백을 반영한 새로운 생성이 일관성을 보장하기 때문이다.

실제 Sprint 실행에서 발견된 경계 조건:
파이프라인에서 산출물은 독립된 소모품이 아니라 **중간 상태(state)**로
사용된다. 같은 정보(예: 데이터 모델)가 PRD, Architecture, Design,
API Spec, Prototype 등 여러 파일에 다른 포맷으로 존재한다.
소규모 수정에 전체 재생성을 적용하면 비용 대비 효과가 역전된다.

```
원칙 3의 전제:  산출물은 독립적 소모품 → 재생성이 항상 효율적
현실의 발견:    산출물은 의존적 중간 상태 → 소규모 수정 시 재생성이 비효율
보정:          수정반영+전파 옵션 추가 + Scope Gate 검증으로 일관성 보장
```

수정반영이 안전한 이유: 원칙 3이 재생성을 기본으로 둔 근거는
"수정이 일관성을 깨뜨린다"는 것이다.
Scope Gate가 수정 후 교차 정합성을 검증하므로,
일관성 파괴 위험이 구조적으로 차단된다.

**원칙은 불변이다.** 재생성이 기본값이고, 수정반영은
시스템이 cost와 함께 제시하는 선택지다. 사용자가 cost를 보고 결정한다.
프로토콜(bmad-sprint-protocol.md)에 구현되어 있으며,
원칙 3 자체는 수정하지 않았다.
